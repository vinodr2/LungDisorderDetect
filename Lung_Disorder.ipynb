{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinodr2/LungDisorderDetect/blob/main/Lung_Disorder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LUNG DISORDER DETECTION SYSTEM**\n",
        "\n",
        "Before downloading the dataset Go to runtime in colab Notebook and change runtime type to T4 GPU"
      ],
      "metadata": {
        "id": "7mjQtGdI2PMi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORT DATASET FROM KAGGLE**\n",
        "\n",
        "1.Import Library: import kagglehub loads the kagglehub library used to download datasets directly from Kaggle.\n",
        "\n",
        "2.Download Dataset: kagglehub.dataset_download(\"preetviradiya/covid19-radiography-dataset\") fetches the COVID-19 Radiography Dataset from Kaggle and saves it locally.\n",
        "\n",
        "3.Show Path: print(\"Path to dataset files:\", path) displays the local path where the dataset was downloaded.\n",
        "\n",
        "\n",
        "To install kagglehub (in built in colab)\n",
        "\n",
        "!pip install kagglehub"
      ],
      "metadata": {
        "id": "pfQl75TwI5Iw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7_4O9rsGQtq"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download COVID-19 Radiography dataset from Kaggle using kagglehub\n",
        "path = kagglehub.dataset_download(\"preetviradiya/covid19-radiography-dataset\")\n",
        "\n",
        "# Print local download path for verification\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MOVE DOWNLOADED PATH TO NOTEBOOK WORKING DIRECTORY**"
      ],
      "metadata": {
        "id": "2NTyZ82MJxLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Source path where KaggleHub saved the dataset\n",
        "source_path = \"/root/.cache/kagglehub/datasets/preetviradiya/covid19-radiography-dataset/versions/2\"\n",
        "\n",
        "# Destination path in Colab\n",
        "destination_path = \"/content/covid_dataset\"\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "\n",
        "# Copy all contents from source to destination\n",
        "shutil.copytree(source_path, destination_path, dirs_exist_ok=True)\n",
        "\n",
        "print(\"Dataset moved to:\", destination_path)\n"
      ],
      "metadata": {
        "id": "alpWx06XJu_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET PROPERTIES AND SELECTION OF IMAGES**\n",
        "\n",
        "1.After Downloading and Moving the dataset to working directory number of categories and number of images located in each categories can be viewed\n",
        "\n",
        "2.Also slection of images for training and testing can be done here based on system requirements this can be adjusted"
      ],
      "metadata": {
        "id": "9zhkK7rBMdMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Input dataset path\n",
        "SOURCE_DIR = \"/content/covid_dataset/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\"\n",
        "\n",
        "# Output dataset path\n",
        "DEST_DIR = \"/content/selected_dataset\"\n",
        "os.makedirs(DEST_DIR, exist_ok=True)\n",
        "\n",
        "# Get category folders\n",
        "categories = [cat for cat in os.listdir(SOURCE_DIR) if os.path.isdir(os.path.join(SOURCE_DIR, cat))]\n",
        "\n",
        "print(\" Available Categories:\\n\")\n",
        "for i, category in enumerate(categories):\n",
        "    print(f\"{i+1}. {category}\")\n",
        "\n",
        "# User selection\n",
        "selected_counts = {}\n",
        "total_selected = 0\n",
        "\n",
        "print(\"\\n Enter number of images to copy from each category:\")\n",
        "\n",
        "for category in categories:\n",
        "    source_path = os.path.join(SOURCE_DIR, category)\n",
        "    all_images = [f for f in os.listdir(source_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    max_images = len(all_images)\n",
        "\n",
        "    # Get user input\n",
        "    while True:\n",
        "        try:\n",
        "            count = int(input(f\"âž¡ {category} (max {max_images}): \"))\n",
        "            if 0 <= count <= max_images:\n",
        "                selected_counts[category] = count\n",
        "                total_selected += count\n",
        "                break\n",
        "            else:\n",
        "                print(f\" Please enter between 0 and {max_images}\")\n",
        "        except:\n",
        "            print(\" Invalid input, try again.\")\n",
        "\n",
        "# Copy images\n",
        "print(\"\\n Copying selected images...\")\n",
        "for category, count in selected_counts.items():\n",
        "    src_folder = os.path.join(SOURCE_DIR, category)\n",
        "    dst_folder = os.path.join(DEST_DIR, category)\n",
        "    os.makedirs(dst_folder, exist_ok=True)\n",
        "\n",
        "    images = [f for f in os.listdir(src_folder) if f.lower().endswith(('.jpg', '.png', '.jpeg'))][:count]\n",
        "\n",
        "    for img in images:\n",
        "        shutil.copy(os.path.join(src_folder, img), os.path.join(dst_folder, img))\n",
        "\n",
        "print(\"\\n All selected images copied to:\", DEST_DIR)\n",
        "\n",
        "# Summary\n",
        "print(\"\\nðŸ“ Summary:\")\n",
        "for cat, count in selected_counts.items():\n",
        "    print(f\" {cat:<20} âž¤ {count} images copied\")\n",
        "\n",
        "print(f\"\\n Total images copied: {total_selected}\")\n"
      ],
      "metadata": {
        "id": "umoKAvT3Mguv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMAGE PREPROCESSING**\n",
        "\n",
        "libraries Needed (N/A for Colab) (**pip install numpy opencv-python matplotlib**)\n",
        "\n",
        "1.Load images from 4 folders: COVID, Lung_Opacity, Normal, Viral Pneumonia.\n",
        "\n",
        "2.Convert to grayscale, enhance contrast (CLAHE), remove noise (median blur), and resize to 150Ã—150.\n",
        "\n",
        "3.Normalize pixel values to 0â€“1 scale for better training.\n",
        "\n",
        "4.Assign labels (0, 1, 2, 3) based on folder order and pair each image with its label.\n",
        "\n",
        "Save processed data into x.pickle and y.pickle for training."
      ],
      "metadata": {
        "id": "K87KkUpSLPTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset path\n",
        "DATA_DIR = \"/content/selected_dataset\"\n",
        "CATEGORIES = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
        "\n",
        "\n",
        "# Image size\n",
        "IMG_SIZE = 150\n",
        "\n",
        "# Data list\n",
        "data = []\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        return None, None\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # CLAHE - Contrast enhancement\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    clahe_img = clahe.apply(gray)\n",
        "\n",
        "    # Median blur - noise reduction\n",
        "    median = cv2.medianBlur(clahe_img, 3)\n",
        "\n",
        "    # Resize\n",
        "    resized = cv2.resize(median, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    # Normalize\n",
        "    normalized = resized / 255.0\n",
        "\n",
        "    return img, normalized\n",
        "\n",
        "# Load and preprocess\n",
        "for label, category in enumerate(CATEGORIES):\n",
        "    path = os.path.join(DATA_DIR, category)\n",
        "    for img_file in os.listdir(path):\n",
        "        img_path = os.path.join(path, img_file)\n",
        "        original, processed = preprocess_image(img_path)\n",
        "        if processed is not None:\n",
        "            data.append((processed, label))\n",
        "\n",
        "# Shuffle\n",
        "random.shuffle(data)\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = zip(*data)\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y = np.array(y)\n",
        "\n",
        "# Save\n",
        "with open(\"x.pickle\", \"wb\") as f:\n",
        "    pickle.dump(X, f)\n",
        "\n",
        "with open(\"y.pickle\", \"wb\") as f:\n",
        "    pickle.dump(y, f)\n",
        "\n",
        "print(\"âœ… Saved enhanced x.pickle and y.pickle\")\n"
      ],
      "metadata": {
        "id": "ny9gYTimLSW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAMPLE IMAGE PREVIEW**\n",
        "\n",
        "The Code below is used to preview the preprocessed image.This code will randomly select images form the preprocessed data\n"
      ],
      "metadata": {
        "id": "-jpu-T56SgQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a sample comparison: original vs preprocessed\n",
        "sample_index = random.randint(0, len(data)-1)\n",
        "category = CATEGORIES[y[sample_index]]\n",
        "original_sample_path = os.path.join(DATA_DIR, category, os.listdir(os.path.join(DATA_DIR, category))[0])\n",
        "original_img = cv2.imread(original_sample_path)\n",
        "original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Resize original image to match preprocessing size\n",
        "original_img_resized = cv2.resize(original_img, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "_, preprocessed_img = preprocess_image(original_sample_path)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(original_img_resized)\n",
        "plt.title(\"Original Image (Resized)\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(preprocessed_img, cmap='gray')\n",
        "plt.title(\"Preprocessed Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-B2aFplaSjKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN RESNET 50 TRAINING**\n",
        "To install Libraries(**pip install numpy matplotlib seaborn opencv-python scikit-learn tensorflow**) N/A for Colab\n",
        "\n",
        "1.Loads grayscale images and labels, converts images to 3-channel for ResNet50.\n",
        "\n",
        "2.Applies ResNet50-specific preprocessing for proper input scaling.\n",
        "\n",
        "3.Splits data into training and testing sets with balanced labels.\n",
        "\n",
        "4.Uses data augmentation (rotate, zoom, shift, flip) to reduce overfitting.\n",
        "\n",
        "5.Builds and trains a model using frozen ResNet50 + dense layers, then evaluates and saves it.\n",
        "\n",
        "6.Key Hyperparameters\n",
        "Epochs: 30 â€” number of training cycles\n",
        "\n",
        "Batch size: 32 â€” samples per update\n",
        "\n",
        "Learning rate: 0.0001 â€” optimizer step size\n",
        "\n",
        "Dropout: 0.5 â€” prevents overfitting\n",
        "\n",
        "Augmentation: rotation Â±15Â°, zoom Â±10%, shift Â±10%, flip â€” increases data diversity"
      ],
      "metadata": {
        "id": "-EaqcLyIxyOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50, resnet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# === Constants ===\n",
        "IMG_SIZE = 150\n",
        "CATEGORIES = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
        "\n",
        "# Save category order for testing\n",
        "with open(\"categories.json\", \"w\") as f:\n",
        "    json.dump(CATEGORIES, f)\n",
        "\n",
        "# === Load Data ===\n",
        "with open(\"x.pickle\", \"rb\") as f:\n",
        "    X = pickle.load(f)  # shape (N, 150, 150, 1)\n",
        "with open(\"y.pickle\", \"rb\") as f:\n",
        "    y = pickle.load(f)\n",
        "\n",
        "# Convert grayscale to 3-channel\n",
        "X_rgb = np.repeat(X, 3, axis=3)\n",
        "\n",
        "# Convert to 0â€“255 uint8 and preprocess for ResNet50\n",
        "X_rgb_uint8 = (X_rgb * 255).astype(np.uint8)\n",
        "X_preprocessed = resnet50.preprocess_input(X_rgb_uint8)\n",
        "\n",
        "# Prepare labels\n",
        "num_classes = len(CATEGORIES)\n",
        "y_cat = to_categorical(y, num_classes)\n",
        "\n",
        "# === Train-Test Split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_preprocessed, y_cat, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# === Data Augmentation to Reduce Overfitting ===\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# === Load ResNet50 Base ===\n",
        "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "resnet_base.trainable = False  # Freeze all layers\n",
        "\n",
        "# Optionally: unfreeze last 20 layers\n",
        "# for layer in resnet_base.layers[-20:]:\n",
        "#     layer.trainable = True\n",
        "\n",
        "# === Build Model ===\n",
        "model = Sequential([\n",
        "    resnet_base,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# === Compile ===\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# === Train ===\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=30\n",
        ")\n",
        "\n",
        "# === Plot Accuracy and Loss ===\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === Evaluate ===\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=CATEGORIES,\n",
        "            yticklabels=CATEGORIES)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=CATEGORIES, digits=4))\n",
        "\n",
        "# === Save Model and Category List ===\n",
        "model.save(\"resnet50_150_model.h5\")\n",
        "print(\"âœ… Model saved as resnet50_150_model.h5\")\n"
      ],
      "metadata": {
        "id": "F0IwupssckmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL SUMMARY**\n",
        "\n",
        "1.ResNet50 base:\n",
        "\n",
        "Outputs feature maps of shape (5, 5, 2048)\n",
        "\n",
        "Has ~23.6 million parameters, all frozen (non-trainable)\n",
        "\n",
        "2.Flatten layer:\n",
        "\n",
        "Flattens the output into a 1D vector of size 51,200\n",
        "\n",
        "No trainable parameters here\n",
        "\n",
        "3.Dense layer (256 units):\n",
        "\n",
        "Fully connected layer with 256 neurons\n",
        "\n",
        "Learns ~13.1 million parameters (trainable)\n",
        "\n",
        "4.Dropout layer (rate 0.5):\n",
        "\n",
        "Randomly drops 50% of neurons during training to reduce overfitting\n",
        "\n",
        "No trainable parameters\n",
        "\n",
        "5.Output Dense layer (4 units):\n",
        "\n",
        "Final classification layer with 4 neurons (one per class)\n",
        "\n",
        "Learns 1,028 parameters\n",
        "\n",
        "6.Total parameters: ~36.7 million\n",
        "\n",
        "Trainable: ~13.1 million (Dense layers only)\n",
        "\n",
        "Non-trainable: ~23.6 million (ResNet50 frozen layers)"
      ],
      "metadata": {
        "id": "NOHdssKA1YZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Ddqilr7b1alu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RESNET TEST CODE**\n",
        "\n",
        "1.Preprocess input image exactly like training (grayscale â†’ CLAHE â†’ blur â†’ resize â†’ convert to 3-channel) and prepare it for ResNet50.\n",
        "\n",
        "2.Load saved model and predict class probabilities for the preprocessed image.\n",
        "\n",
        "3.Display original image, prediction, confidence scores, and predicted classes for clear interpretation."
      ],
      "metadata": {
        "id": "4VSCam95gRVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "# === Constants ===\n",
        "IMG_SIZE = 150\n",
        "MODEL_PATH = \"/content/resnet50_150_model.h5\"  # Change if needed\n",
        "CATEGORIES = ['COVID', 'Lung_Opacity', 'Normal', 'Viral_Pneumonia']\n",
        "\n",
        "# === Preprocessing Function (MUST match training) ===\n",
        "def preprocess_image(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(f\"âŒ Error loading image: {img_path}\")\n",
        "        return None, None\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # CLAHE - enhance contrast\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    clahe_img = clahe.apply(gray)\n",
        "\n",
        "    # Median blur\n",
        "    median = cv2.medianBlur(clahe_img, 3)\n",
        "\n",
        "    # Resize to match model input\n",
        "    resized = cv2.resize(median, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    # Convert grayscale back to 3-channel BGR\n",
        "    img_3ch = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    return img, img_3ch\n",
        "\n",
        "# === Input image path ===\n",
        "img_path = input(\"Enter path to test chest X-ray image: \").strip()\n",
        "\n",
        "# === Load and preprocess the image ===\n",
        "original_img, img_for_model = preprocess_image(img_path)\n",
        "if img_for_model is None:\n",
        "    exit(\"âš ï¸ Preprocessing failed.\")\n",
        "\n",
        "# === Convert to uint8 and preprocess for ResNet50 ===\n",
        "img_uint8 = img_for_model.astype(np.uint8)  # already in 0â€“255\n",
        "processed_input = preprocess_input(img_uint8)\n",
        "input_img = processed_input.reshape(1, IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# === Load trained model ===\n",
        "model = load_model(MODEL_PATH)\n",
        "\n",
        "# === Predict ===\n",
        "prediction = model.predict(input_img)[0]\n",
        "predicted_class = CATEGORIES[np.argmax(prediction)]\n",
        "\n",
        "# === Display original and prediction ===\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(cv2.cvtColor(img_for_model, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f\"Predicted: {predicted_class}\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# === Show Prediction Scores ===\n",
        "print(\"\\n Prediction Scores:\")\n",
        "for i, category in enumerate(CATEGORIES):\n",
        "    print(f\"{category}: {prediction[i]:.4f}\")\n",
        "\n",
        "# === Show Top 3 Predictions ===\n",
        "top_3_indices = prediction.argsort()[-3:][::-1]\n",
        "print(\"\\n Top 3 Predictions:\")\n",
        "for idx in top_3_indices:\n",
        "    print(f\"{CATEGORIES[idx]}: {prediction[idx]:.4f}\")\n"
      ],
      "metadata": {
        "id": "8TxkiWp2gTSt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}